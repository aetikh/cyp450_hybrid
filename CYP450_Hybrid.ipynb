{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before running this code, ensure that you have the following set of descriptors. You can find a full set of used descriptors in the Supplementary Information, Table 4.\n",
        "\n",
        "1.  Physocochemical descriptors of ligands (calculated using KNIME Analytics  platform, use CDK Molecular Properties, Indigo Molecule Properties and RDKit Descriptor Calculation nodes)\n",
        "\n",
        "2. Protein descriptors should be calculated in iFeature python package (https://github.com/Superzchen/iFeature)\n",
        "\n",
        "3. Rescore the docking poses obtained from Glide using ITScore_Aff (http://huanglab.phys.hust.edu.cn/ITScoreAff/) and Cyscore (http://clab.labshare.cn/software/) scoring functions.\n",
        "\n",
        "4. Extract the docking descriptors from Glide and calculate SIFt descriptors (Tasks -> Interaction Fingerprints)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "DUD-E decoys should be prepared to represent non-binding molecules (https://dude.docking.org/). To better simulate a real-world virtual screening scenario, the number of DUD-E decoys should be approximately 50 times greater than the size of your ligand dataset.\n"
      ],
      "metadata": {
        "id": "ShoEwuf7xykP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmya_mM5xruu"
      },
      "outputs": [],
      "source": [
        "#Install required libraries\n",
        "pip install autogluon\n",
        "pip install PyTDC\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score, fbeta_score\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from autogluon.core.metrics import make_scorer\n",
        "from tdc import Evaluator\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your dataset. Your data should be organized in a tabular structure, where each line represents a docking pose of CYP450-ligand binding and each column represents one of the associated descriptors (listed in Supplemen\n",
        "tary Information, Table 4). Ligand and protein descriptors\n",
        "associated of the used crystal structure and SMILES ligand are also included in the line. \"Class\" column should be binary and represent whether this molecule is a ligand or decoy."
      ],
      "metadata": {
        "id": "BBSGWY4E2HWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload your training and validation dataset\n",
        "train_data = TabularDataset('train_dataset.csv')\n",
        "test_data = TabularDataset('validation_dataset.csv')\n",
        "label = \"Class\""
      ],
      "metadata": {
        "id": "L0FcG7pVA2OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add logAUC metric\n",
        "evaluator = Evaluator(name=\"range_logAUC\")\n",
        "ag_logauc_scorer = make_scorer(name=\"evaluator\", score_func=evaluator, optimum=1, greater_is_better=True)"
      ],
      "metadata": {
        "id": "qV-w1-WVB5sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we aim to perform multiple model iterations for statistical analysis, each iteration should be assigned a unique identifier to enable individual access and evaluation. \"Medium\" is a default Autogluon preset, which provides fast training time, ideal for initial prototyping. For more customisation we recommend you to set max number of epochs and num_workers parameters according to your computational resources availability. Autogluon uses max_epochs = 10 as a default, but you can increase this parameter if your data has complex patterns. Optimize num_workers according to your available GPU. The details for customization are described here https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html."
      ],
      "metadata": {
        "id": "a8_rm4GK7_P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Start training\n",
        "model_path = f\"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "print(f\"Training has started. The results will be saved in {model_path}\")\n",
        "\n",
        "predictor = TabularPredictor(label=label, path=model_path, eval_metric=ag_logauc_scorer).fit(\n",
        "    train_data,\n",
        "    presets=\"medium\"\n",
        ")\n",
        "\n",
        "print(\"Training is complete\")\n"
      ],
      "metadata": {
        "id": "tgHMrmTs6xzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate validation results using LogAUC. Autogluon also provides preselected metrics, such as ROC_AUC and Matthews Correlation Coefficient. You can add additional metrics (e.g. AUPR, F2) by editing \"evaluate\" function"
      ],
      "metadata": {
        "id": "7No7YIphSUj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate validation results\n",
        "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
        "metrics = predictor.evaluate(test_data, silent=True)\n",
        "print(f\"Test metrics: {metrics}\")"
      ],
      "metadata": {
        "id": "EK9bqmyxV61n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save test metrics to a separate CSV file\n",
        "eval_path = f\"evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(eval_path, exist_ok=True)\n",
        "metrics_df = pd.DataFrame([metrics])  # Convert dict to DataFrame\n",
        "metrics_df.to_csv(f\"{eval_path}/test_metrics.csv\", index=False)\n",
        "print(f\"Test metrics saved to {eval_path}/test_metrics.csv\")"
      ],
      "metadata": {
        "id": "TLQDUZpjSaaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}